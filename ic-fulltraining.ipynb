{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Multiclass Image Classification Example\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "  1. [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "  2. [Prepare the data](#Prepare-the-data)\n",
    "3. [Training the model](#Training-the-model)\n",
    "  1. [Training parameters](#Training-parameters)\n",
    "  2. [Start the training](#Start-the-training)\n",
    "4. [Compile](#Compile)\n",
    "5. [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "이 데모에서는 Amazon Sagemaker 의 이미지 분류 알고리즘을 이용해서, [caltech-256 dataset](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)를 학습합니다. \n",
    "\n",
    "시작하기에 앞서, 몇 가지 환경 설정과, 인증 설정이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and Preprocessing\n",
    "\n",
    "### Permissions and environment variables\n",
    "\n",
    "AWS 서비스로의 연결과 권한 설정을 진행합니다. 이 단계의 세 가지 목표는:\n",
    "\n",
    "* 학습과 데이터에 대한 역할 생성. 노트북 인스턴스를 생성할 때에, 자동으로 부여됩니다.\n",
    "* 학습 데이터와 모델 데이터를 위한 S3 버킷\n",
    "* Amazon SageMaker 이미지 분류 도커 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"ic-fulltraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region=sess.boto_region_name, framework=\"image-classification\", version=\"latest\"\n",
    ")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "학습 데이터를 다운받고, S3 에 업로드합니다. 이 데모에서는 256가지 종류로 나뉘어진 30607장의 이미지를 제공하는 [Caltech-256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/) 데이터셋을 이용하여 학습을 진행합니다. 학습과 검증 데이터셋을 나누기 위해서, MXNet 예제와 같은 방식으로 데이터셋을 분할합니다. 각각의 클래스별로 60장의 이미지를 무작위로 선택하여 학습 데이터로 사용하고, 나머지 데이터는 검증 데이터로 이용합니다. Image Classification 알고리즘은 RecordIO 파일을 인풋으로 받습니다. 사용자는 이미지 파일을 인풋으로 제공할 수도 있으며, MXNet의 [im2rec](https://mxnet.incubator.apache.org/how_to/recordio.html?highlight=im2rec) 툴을 이용해서 RecordIO 형식으로 변환됩니다. p2.xlarge 인스턴스에서 전체 Caltech-256 데이터셋 (~1.2GB) 를 변환하는 데에 약 50초 정도가 소요됩니다. 하지만, 이 데모에서는 RecordIO 형식으로 제공되는 데이터셋을 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import boto3\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "def upload_to_s3(channel, file):\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    data = open(file, \"rb\")\n",
    "    key = channel + \"/\" + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "\n",
    "# caltech-256\n",
    "download(\"http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec\")\n",
    "download(\"http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four channels: train, validation, train_lst, and validation_lst\n",
    "s3train = \"s3://{}/{}/train/\".format(bucket, prefix)\n",
    "s3validation = \"s3://{}/{}/validation/\".format(bucket, prefix)\n",
    "\n",
    "# upload the lst files to train and validation channels\n",
    "!aws s3 cp caltech-256-60-train.rec $s3train --quiet\n",
    "!aws s3 cp caltech-256-60-val.rec $s3validation --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터가 적합한 형식으로 준비가 되면, 다음 단계는 데이터를 이용하여 학습을 진행하는 것 입니다. 학습 파라미터를 설정하고, 학습을 시작한 후, 진행 상황을 받아옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 설정을 마쳤으면, 사물 인식 모델을 학습할 준비가 되었습니다. 시작하기 위해, ``sageMaker.estimator.Estimator`` 객체를 생성합니다. Estimator 는 학습 작업을 시작합니다.\n",
    "\n",
    "## 학습 파라미터\n",
    "학습을 위해 설정되어야 할 파라미터에는 두 가지 종류가 있습니다. 첫 번째로는\n",
    "\n",
    "* **학습 인스턴스 개수**: 학습을 위해 사용될 인스턴스의 개수입니다. 두 개 이상의 인스턴스를 사용할 경우, 분산 학습으로 진행됩니다.\n",
    "* **학습 인스턴스 종류**: 학습을 위해 사용될 인스턴스의 종류입니다. 대부분 GPU 인스턴스를 사용합니다.\n",
    "* **출력 경로**: 학습의 결과가 저장될 S3 폴더입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "ic = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    volume_size=50,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "위의 파라미터와 별개로, 알고리즘마다 설정되는 하이퍼파라미터가 있습니다:\n",
    "\n",
    "* **num_layers**: 뉴럴 네트워크의 레이어 개수(깊이). 이 데모에서는 18개의 레이어를 사용하지만, 50, 152 와 같이 큰 숫자도 사용 가능합니다.\n",
    "* **image_shape**: 입력 이미지의 크기입니다. ‘채널 수, 높이, 너비’가 있으며, 실제 이미지 사이즈보다 커서는 안 되고, 채널 수는 실제 이미지의 채널 수와 같아야 합니다.\n",
    "* **num_classes**: 데이터셋의 클래스 개수입니다. Imagenet 은 100개의 클래스로 학습되었지만, fine-tuning 과정에서 바뀔 수 있습니다. Caltech 데이터셋은 257개 (256개의 사물 카테고리 + 클러스터) 의 클래스를 사용합니다.\n",
    "* **num_training_samples**: 학습 샘플의 개수입니다. Caltech 데이터셋은 분할 이후 15240개의 학습 샘플이 있습니다.\n",
    "* **mini_batch_size**: 미니 배치에 있는 학습 샘플의 개수입니다. 분산 학습에서는 N * mini_batch_size 만큼의 학습 샘플이 배치마다 사용되고, 여기서 N은 학습에 사용된 인스턴스의 개수입니다.\n",
    "* **epochs**: Epoch 의 수입니다.\n",
    "* **learning_rate**: Learning rate 의 값입니다.\n",
    "* **top_k**: 학습 중 top-k 정확도를 출력합니다.\n",
    "* **precision_dtype**: 학습의 데이터형입니다. (Deafult: float32). ‘Float16’으로 설정될 경우, mixed_precision 모드로 학습이 진행되며 float32 모드보다 빠르게 학습이 될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.set_hyperparameters(\n",
    "    num_layers=18,\n",
    "    image_shape=\"3,224,224\",\n",
    "    num_classes=257,\n",
    "    num_training_samples=15420,\n",
    "    mini_batch_size=128,\n",
    "    epochs=5,\n",
    "    learning_rate=0.01,\n",
    "    top_k=2,\n",
    "    precision_dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data specification\n",
    "데이터형과 채널을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3train,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3validation,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training\n",
    "Fit 함수를 이용하여 학습을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile\n",
    "\n",
    "***\n",
    "\n",
    "[Amazon SageMaker Neo](https://aws.amazon.com/sagemaker/neo/) 은 모델이 두 배 빠르게 작동할 수 있도록 최적화를 시킵니다. `compile_model()`함수를 통해서, 인스턴스 종류 (m4) 와 컴파일된 모델이 저장될 s3 버킷을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/\".join(ic.output_path.split(\"/\")[:-1])\n",
    "optimized_ic = ic.compile_model(\n",
    "    target_instance_family=\"ml_m4\",\n",
    "    input_shape={\"data\": [1, 3, 224, 224]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "    output_path=output_path,\n",
    "    framework=\"mxnet\",\n",
    "    framework_version=\"1.8\",\n",
    "    env={\"MMS_DEFAULT_RESPONSE_TIMEOUT\": \"500\"},\n",
    ")\n",
    "optimized_ic.image = image_uris.retrieve(\n",
    "    region=sess.boto_region_name, framework=\"image-classification-neo\", version=\"latest\"\n",
    ")\n",
    "optimized_ic.name = \"deployed-image-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "\n",
    "s3_custom_code_location = \"s3://{}/{}/custom_code\".format(bucket, prefix)\n",
    "\n",
    "optimized_ic_model = MXNetModel(\n",
    "    model_data=optimized_ic.model_data,\n",
    "    image_uri=optimized_ic.image_uri,\n",
    "    framework_version=\"1.8\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    entry_point=\"inference.py\",\n",
    "    py_version=\"py37\",\n",
    "    env={\"MMS_DEFAULT_RESPONSE_TIMEOUT\": \"500\"},\n",
    "    code_location=s3_custom_code_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "***\n",
    "\n",
    "학습된 모델은 그 자체로서는 아무것도 하지 못합니다. 모델을 추론을 위해 사용할 수 있도록 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = optimized_ic_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", use_compiled_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O test.jpg http://sagemaker-sample-files.s3.amazonaws.com/datasets/image/caltech-256/256_ObjectCategories/008.bathtub/008_0007.jpg\n",
    "file_name = \"test.jpg\"\n",
    "# test image\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "추론을 위해서 이미지를 분석합니다. 모델은 이미지 분류 클래스에 대한 확률을 출력하고, 대부분 가장 큰 확률이 있는 클래스를 선택합니다.\n",
    "\n",
    "**Note:** 현재는 모델의 성능이 좋지 않을 수 있습니다. 시간 절약을 위해서 이 데모에서는 5 epoch 동안만 학습을 진행하였고, 더 많은 epoch (20 정도) 동안 학습이 된다면, 모델의 성능이 향상될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "test_image = PIL.Image.open(file_name)\n",
    "payload = np.asarray(test_image.resize((224, 224)))\n",
    "\n",
    "result = ic_classifier.predict(payload)\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n",
    "index = np.argmax(result)\n",
    "object_categories = [\n",
    "    \"ak47\",\n",
    "    \"american-flag\",\n",
    "    \"backpack\",\n",
    "    \"baseball-bat\",\n",
    "    \"baseball-glove\",\n",
    "    \"basketball-hoop\",\n",
    "    \"bat\",\n",
    "    \"bathtub\",\n",
    "    \"bear\",\n",
    "    \"beer-mug\",\n",
    "    \"billiards\",\n",
    "    \"binoculars\",\n",
    "    \"birdbath\",\n",
    "    \"blimp\",\n",
    "    \"bonsai-101\",\n",
    "    \"boom-box\",\n",
    "    \"bowling-ball\",\n",
    "    \"bowling-pin\",\n",
    "    \"boxing-glove\",\n",
    "    \"brain-101\",\n",
    "    \"breadmaker\",\n",
    "    \"buddha-101\",\n",
    "    \"bulldozer\",\n",
    "    \"butterfly\",\n",
    "    \"cactus\",\n",
    "    \"cake\",\n",
    "    \"calculator\",\n",
    "    \"camel\",\n",
    "    \"cannon\",\n",
    "    \"canoe\",\n",
    "    \"car-tire\",\n",
    "    \"cartman\",\n",
    "    \"cd\",\n",
    "    \"centipede\",\n",
    "    \"cereal-box\",\n",
    "    \"chandelier-101\",\n",
    "    \"chess-board\",\n",
    "    \"chimp\",\n",
    "    \"chopsticks\",\n",
    "    \"cockroach\",\n",
    "    \"coffee-mug\",\n",
    "    \"coffin\",\n",
    "    \"coin\",\n",
    "    \"comet\",\n",
    "    \"computer-keyboard\",\n",
    "    \"computer-monitor\",\n",
    "    \"computer-mouse\",\n",
    "    \"conch\",\n",
    "    \"cormorant\",\n",
    "    \"covered-wagon\",\n",
    "    \"cowboy-hat\",\n",
    "    \"crab-101\",\n",
    "    \"desk-globe\",\n",
    "    \"diamond-ring\",\n",
    "    \"dice\",\n",
    "    \"dog\",\n",
    "    \"dolphin-101\",\n",
    "    \"doorknob\",\n",
    "    \"drinking-straw\",\n",
    "    \"duck\",\n",
    "    \"dumb-bell\",\n",
    "    \"eiffel-tower\",\n",
    "    \"electric-guitar-101\",\n",
    "    \"elephant-101\",\n",
    "    \"elk\",\n",
    "    \"ewer-101\",\n",
    "    \"eyeglasses\",\n",
    "    \"fern\",\n",
    "    \"fighter-jet\",\n",
    "    \"fire-extinguisher\",\n",
    "    \"fire-hydrant\",\n",
    "    \"fire-truck\",\n",
    "    \"fireworks\",\n",
    "    \"flashlight\",\n",
    "    \"floppy-disk\",\n",
    "    \"football-helmet\",\n",
    "    \"french-horn\",\n",
    "    \"fried-egg\",\n",
    "    \"frisbee\",\n",
    "    \"frog\",\n",
    "    \"frying-pan\",\n",
    "    \"galaxy\",\n",
    "    \"gas-pump\",\n",
    "    \"giraffe\",\n",
    "    \"goat\",\n",
    "    \"golden-gate-bridge\",\n",
    "    \"goldfish\",\n",
    "    \"golf-ball\",\n",
    "    \"goose\",\n",
    "    \"gorilla\",\n",
    "    \"grand-piano-101\",\n",
    "    \"grapes\",\n",
    "    \"grasshopper\",\n",
    "    \"guitar-pick\",\n",
    "    \"hamburger\",\n",
    "    \"hammock\",\n",
    "    \"harmonica\",\n",
    "    \"harp\",\n",
    "    \"harpsichord\",\n",
    "    \"hawksbill-101\",\n",
    "    \"head-phones\",\n",
    "    \"helicopter-101\",\n",
    "    \"hibiscus\",\n",
    "    \"homer-simpson\",\n",
    "    \"horse\",\n",
    "    \"horseshoe-crab\",\n",
    "    \"hot-air-balloon\",\n",
    "    \"hot-dog\",\n",
    "    \"hot-tub\",\n",
    "    \"hourglass\",\n",
    "    \"house-fly\",\n",
    "    \"human-skeleton\",\n",
    "    \"hummingbird\",\n",
    "    \"ibis-101\",\n",
    "    \"ice-cream-cone\",\n",
    "    \"iguana\",\n",
    "    \"ipod\",\n",
    "    \"iris\",\n",
    "    \"jesus-christ\",\n",
    "    \"joy-stick\",\n",
    "    \"kangaroo-101\",\n",
    "    \"kayak\",\n",
    "    \"ketch-101\",\n",
    "    \"killer-whale\",\n",
    "    \"knife\",\n",
    "    \"ladder\",\n",
    "    \"laptop-101\",\n",
    "    \"lathe\",\n",
    "    \"leopards-101\",\n",
    "    \"license-plate\",\n",
    "    \"lightbulb\",\n",
    "    \"light-house\",\n",
    "    \"lightning\",\n",
    "    \"llama-101\",\n",
    "    \"mailbox\",\n",
    "    \"mandolin\",\n",
    "    \"mars\",\n",
    "    \"mattress\",\n",
    "    \"megaphone\",\n",
    "    \"menorah-101\",\n",
    "    \"microscope\",\n",
    "    \"microwave\",\n",
    "    \"minaret\",\n",
    "    \"minotaur\",\n",
    "    \"motorbikes-101\",\n",
    "    \"mountain-bike\",\n",
    "    \"mushroom\",\n",
    "    \"mussels\",\n",
    "    \"necktie\",\n",
    "    \"octopus\",\n",
    "    \"ostrich\",\n",
    "    \"owl\",\n",
    "    \"palm-pilot\",\n",
    "    \"palm-tree\",\n",
    "    \"paperclip\",\n",
    "    \"paper-shredder\",\n",
    "    \"pci-card\",\n",
    "    \"penguin\",\n",
    "    \"people\",\n",
    "    \"pez-dispenser\",\n",
    "    \"photocopier\",\n",
    "    \"picnic-table\",\n",
    "    \"playing-card\",\n",
    "    \"porcupine\",\n",
    "    \"pram\",\n",
    "    \"praying-mantis\",\n",
    "    \"pyramid\",\n",
    "    \"raccoon\",\n",
    "    \"radio-telescope\",\n",
    "    \"rainbow\",\n",
    "    \"refrigerator\",\n",
    "    \"revolver-101\",\n",
    "    \"rifle\",\n",
    "    \"rotary-phone\",\n",
    "    \"roulette-wheel\",\n",
    "    \"saddle\",\n",
    "    \"saturn\",\n",
    "    \"school-bus\",\n",
    "    \"scorpion-101\",\n",
    "    \"screwdriver\",\n",
    "    \"segway\",\n",
    "    \"self-propelled-lawn-mower\",\n",
    "    \"sextant\",\n",
    "    \"sheet-music\",\n",
    "    \"skateboard\",\n",
    "    \"skunk\",\n",
    "    \"skyscraper\",\n",
    "    \"smokestack\",\n",
    "    \"snail\",\n",
    "    \"snake\",\n",
    "    \"sneaker\",\n",
    "    \"snowmobile\",\n",
    "    \"soccer-ball\",\n",
    "    \"socks\",\n",
    "    \"soda-can\",\n",
    "    \"spaghetti\",\n",
    "    \"speed-boat\",\n",
    "    \"spider\",\n",
    "    \"spoon\",\n",
    "    \"stained-glass\",\n",
    "    \"starfish-101\",\n",
    "    \"steering-wheel\",\n",
    "    \"stirrups\",\n",
    "    \"sunflower-101\",\n",
    "    \"superman\",\n",
    "    \"sushi\",\n",
    "    \"swan\",\n",
    "    \"swiss-army-knife\",\n",
    "    \"sword\",\n",
    "    \"syringe\",\n",
    "    \"tambourine\",\n",
    "    \"teapot\",\n",
    "    \"teddy-bear\",\n",
    "    \"teepee\",\n",
    "    \"telephone-box\",\n",
    "    \"tennis-ball\",\n",
    "    \"tennis-court\",\n",
    "    \"tennis-racket\",\n",
    "    \"theodolite\",\n",
    "    \"toaster\",\n",
    "    \"tomato\",\n",
    "    \"tombstone\",\n",
    "    \"top-hat\",\n",
    "    \"touring-bike\",\n",
    "    \"tower-pisa\",\n",
    "    \"traffic-light\",\n",
    "    \"treadmill\",\n",
    "    \"triceratops\",\n",
    "    \"tricycle\",\n",
    "    \"trilobite-101\",\n",
    "    \"tripod\",\n",
    "    \"t-shirt\",\n",
    "    \"tuning-fork\",\n",
    "    \"tweezer\",\n",
    "    \"umbrella-101\",\n",
    "    \"unicorn\",\n",
    "    \"vcr\",\n",
    "    \"video-projector\",\n",
    "    \"washing-machine\",\n",
    "    \"watch-101\",\n",
    "    \"waterfall\",\n",
    "    \"watermelon\",\n",
    "    \"welding-mask\",\n",
    "    \"wheelbarrow\",\n",
    "    \"windmill\",\n",
    "    \"wine-bottle\",\n",
    "    \"xylophone\",\n",
    "    \"yarmulke\",\n",
    "    \"yo-yo\",\n",
    "    \"zebra\",\n",
    "    \"airplanes-101\",\n",
    "    \"car-side-101\",\n",
    "    \"faces-easy-101\",\n",
    "    \"greyhound\",\n",
    "    \"tennis-shoes\",\n",
    "    \"toad\",\n",
    "    \"clutter\",\n",
    "]\n",
    "print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "\n",
    "데모 진행이 완료되었으면, 배포 엔드포인트를 삭제합니다. 아래 코드를 주석 해제한 후, 실행하여 엔드포인트와 모델을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier.delete_model()\n",
    "ic_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
